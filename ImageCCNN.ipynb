{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTIY5mB_OSET",
        "outputId": "649f6077-6a89-4b92-94d1-add4b1f1ee36"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Off73NPJRx0t"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6NvlclJTMIV"
      },
      "source": [
        "#Checking for device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngcwgt3Tg-b",
        "outputId": "c0de650b-7401-43e5-d86f-8a23ed8aae93"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y_7GKhlUXI_"
      },
      "source": [
        "#Transform for dataprocessing resize images, add augmintation technique to increase orignal image\n",
        "#ToTensor change pixel color and change the range , matrix col rep RGB, rows rep mean and std deviation \n",
        "transformer=transforms.Compose([\n",
        "                                transforms.Resize((150,150)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(), # 0 - 255 to 0 - 1 numpy to tensors\n",
        "                                transforms.Normalize([0.5, 0.5, 0.5], \n",
        "                                [0.5, 0.5, 0.5]) # 0-1 to [-1, 1], formula (x-mean)/std\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfqMwIzrV6dg"
      },
      "source": [
        "#DataLoader\n",
        "train_path='/content/drive/MyDrive/scene_detection/seg_train/seg_train'\n",
        "test_path= '/content/drive/MyDrive/scene_detection/seg_test/seg_test'\n",
        "\n",
        "\n",
        "train_loader = DataLoader(torchvision.datasets.ImageFolder(train_path, transform=transformer),\n",
        "                          batch_size=256, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(torchvision.datasets.ImageFolder(test_path, transform=transformer),\n",
        "                          batch_size=32, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uZV1rCszBTE"
      },
      "source": [
        "#categories\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unMr4ie8zbbW",
        "outputId": "3c811915-aec2-4048-de0a-3aaf4860df3a"
      },
      "source": [
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyjZnZ63zi-b"
      },
      "source": [
        "#CNN Network Class\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, num_classes=6):\n",
        "    super(ConvNet,self).__init__()\n",
        "\n",
        "    #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "\n",
        "    ##Input shape= (256,3,150,150)\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    #shape= (256,12,150,150)\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=12)\n",
        "    self.relu1 = nn.ReLU()\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "    #Reduce the image size be factor 2\n",
        "    #Shape= (256,12,75,75)\n",
        "\n",
        "    #Add second Convolution layer and relu layer shape is (256,20,75,75)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    \n",
        "    #Add third Convolution layer and relu layer shape is (256,32,75,75)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(num_features=32)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    \n",
        "    #Adding fully connected layer we feed  input feature which is d, h and image of C layer output\n",
        "    self.fc = nn.Linear(in_features= 75 * 75 * 32, out_features = num_classes)\n",
        "\n",
        "  #Feed forward function\n",
        "  def forward(self, input):\n",
        "    output = self.conv1(input)\n",
        "    output = self.bn1(output)\n",
        "    output = self.relu1(output)\n",
        "\n",
        "    output = self.pool(output)\n",
        "\n",
        "    output = self.conv2(output)\n",
        "    output = self.relu2(output)\n",
        "\n",
        "    output = self.conv3(output)\n",
        "    output = self.bn3(output)\n",
        "    output = self.relu3(output)\n",
        "\n",
        "                #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "    #reshape function then feed inside\n",
        "    output = output.view(-1,32 * 75 * 75 )\n",
        "    output = self.fc(output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZnJJMet4u-g"
      },
      "source": [
        "model = ConvNet(num_classes=6).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wgfkyCY447C"
      },
      "source": [
        "#Calling Optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xVfO01F5L5n"
      },
      "source": [
        "num_epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rflqxr655SIp"
      },
      "source": [
        "#claculating the size of traning and testing images using glob.glob func\n",
        "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count = len(glob.glob(test_path+'/**/*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZfPMNu45xIL",
        "outputId": "a03d959a-35ad-4fa8-d805-70732af8bc43"
      },
      "source": [
        "print(train_count, test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14034 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWFCAT-t6L1U",
        "outputId": "1bcf3f67-a5d0-4740-e3aa-8667f71bfde9"
      },
      "source": [
        "#Model training and saving best model\n",
        "#And calculate traing and testing loss for each epoch \n",
        "\n",
        "best_acc = 0.0 # will update inside loop for each epoc\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  #evaluate traning and testing dataset\n",
        "  model.train() # o train traning data \n",
        "  train_acc = 0.0\n",
        "  train_loss = 0.0\n",
        "\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    if torch.cuda.is_available():\n",
        "      images = Variable(images.cuda())\n",
        "      labels = Variable(labels.cuda())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(images) #it give us prediction\n",
        "    loss = loss_function(output,labels) #predicted and actual value the loss\n",
        "    loss.backward()\n",
        "    optimizer.step()#will updated the weight and bais\n",
        "\n",
        "    train_loss += loss.cpu().data*images.size(0)\n",
        "    _,prediction = torch.max(output.data,1)\n",
        "\n",
        "    train_acc += int(torch.sum(prediction == labels.data))\n",
        "\n",
        "  train_acc = train_acc/train_count\n",
        "  train_loss = train_loss/train_count\n",
        "\n",
        "  # Evaluation on testing dataset\n",
        "  model.eval()\n",
        "\n",
        "  test_acc = 0.0\n",
        "  for i, (images,labels) in enumerate(test_loader):\n",
        "      if torch.cuda.is_available():\n",
        "          images=Variable(images.cuda())\n",
        "          labels=Variable(labels.cuda())\n",
        "\n",
        "      output = model(images)\n",
        "      _,prediction=torch.max(output.data,1)\n",
        "      test_acc += int(torch.sum(prediction == labels.data))\n",
        "\n",
        "  test_acc = test_acc/test_count\n",
        "\n",
        "  print('Epoch: '+str(epoch)+ 'Train Loss: '+str(train_loss)+ 'Train Accuracy: '+str(train_acc)+ \n",
        "        'Test Accuracy: '+str(test_acc))\n",
        "      \n",
        "  #save the best model\n",
        "  if test_acc > best_acc:\n",
        "    torch.save(model.state_dict(), 'best_checkpoint.model')\n",
        "    best_acc = test_acc    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0Train Loss: tensor(1.0986)Train Accuracy: 0.7496793501496366Test Accuracy: 0.6186666666666667\n",
            "Epoch: 1Train Loss: tensor(0.8670)Train Accuracy: 0.8043323357560211Test Accuracy: 0.7223333333333334\n",
            "Epoch: 2Train Loss: tensor(0.5321)Train Accuracy: 0.8664671512042184Test Accuracy: 0.7236666666666667\n",
            "Epoch: 3Train Loss: tensor(0.3954)Train Accuracy: 0.8954681487815306Test Accuracy: 0.7163333333333334\n",
            "Epoch: 4Train Loss: tensor(0.2700)Train Accuracy: 0.9248966794926606Test Accuracy: 0.7\n",
            "Epoch: 5Train Loss: tensor(0.2336)Train Accuracy: 0.9350149636596836Test Accuracy: 0.7536666666666667\n",
            "Epoch: 6Train Loss: tensor(0.1807)Train Accuracy: 0.9474134245404019Test Accuracy: 0.756\n",
            "Epoch: 7Train Loss: tensor(0.1010)Train Accuracy: 0.9692888698874162Test Accuracy: 0.7636666666666667\n",
            "Epoch: 8Train Loss: tensor(0.1550)Train Accuracy: 0.9520450334900955Test Accuracy: 0.753\n",
            "Epoch: 9Train Loss: tensor(0.0869)Train Accuracy: 0.9724241128687473Test Accuracy: 0.7746666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db51HUtw1MlE"
      },
      "source": [
        ""
      ]
    }
  ]
}